{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning - Practicum 6 - Convolutional Neural Network\n",
    "\n",
    "**Topics covered**: Convolutional Neural Network\n",
    "\n",
    "**Deliverables**:\n",
    "- Complete the tasks as detailed in this document.  <br>\n",
    "- The keras model file `mymodel.h5` (see Task 2 for detail). <br>\n",
    "This practice uses [Keras](https://keras.io/api/) with Tensorflow.\n",
    "\n",
    "**Objectives**:\n",
    "After completing the tasks, you'll know how to:\n",
    "- implement a simplified 7-layer LeNet CNN, and <br>\n",
    "- apply it for object recognition. <br>\n",
    "- design and implement a convnet model on a given data set. <br>\n",
    "\n",
    "---\n",
    "Import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf    # one-hot encode\n",
    "from PIL import Image\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Task 1 - Implement a convnet\n",
    "\n",
    "### 1.1 Load image and Get train, test data set\n",
    "The facial images are frm **olivettifaces** we used before. <br>\n",
    "There are ten different images of each of 40 distinct subjects. The image is quantized to 256 grey levels and stored as unsigned 8-bit integers. Size of each image is 57 by 47 with 1 channel.<br>\n",
    "In order to adapt to convnets, the data and target need to be reshaped. <br>\n",
    "Run code in cell below to get `train_data`, `train_target`, `test_data`, `test_target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and normalize face image data\n",
    "def load_images(filename):\n",
    "    \n",
    "    # open files, use Image.open()\n",
    "    img = Image.open(filename)\n",
    "    \n",
    "    # Normalize pixle values, let it with range [0,1]\n",
    "    img_ndarray = np.asarray(img, dtype='float32')/255\n",
    "    \n",
    "    # Split the entire image into 400 samples\n",
    "    faces = np.empty((400,2679),dtype='float32')\n",
    "    for row in range(20):\n",
    "        for column in range(20):\n",
    "            faces[row*20+column] = np.ndarray.flatten(img_ndarray[row*57:(row+1)*57,column*47:(column+1)*47])\n",
    "            \n",
    "    # Create target array    \n",
    "    target = np.empty(400)\n",
    "    for i in range(40):\n",
    "        target[i*10:i*10+10]=i\n",
    "\n",
    "    target=target.astype(np.int)\n",
    "    \n",
    "    #train, validation\n",
    "    train_data=np.empty((360,2679),dtype='float32')\n",
    "    train_target=np.empty(360)\n",
    "    test_data=np.empty((40,2679),dtype='float32')\n",
    "    test_target=np.empty(40)\n",
    "\n",
    "    for i in range(40):\n",
    "        train_data[i*9:i*9+9]=faces[i*10:i*10+9]\n",
    "        train_target[i*9:i*9+9]=target[i*10:i*10+9]\n",
    "        test_data[i]=faces[i*10+9]\n",
    "        test_target[i]=target[i*10+9]\n",
    "        \n",
    "    # reshape\n",
    "    train_data = train_data.reshape((360,57,47,1))\n",
    "    test_data = test_data.reshape((40,57,47,1))\n",
    "    \n",
    "    # one-hot encode for target\n",
    "    train_target = tf.keras.utils.to_categorical(train_target)\n",
    "    test_target = tf.keras.utils.to_categorical(test_target)    \n",
    "        \n",
    "    return train_data, train_target, test_data, test_target\n",
    "\n",
    "train_data, train_target, test_data, test_target = load_images(\"olivettifaces.gif\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Build Convnet model\n",
    "Implement function `build_CNN()` to build the convnet described as following: <br>\n",
    "1)\tLayer 0 - conv2d_1 (Conv2D), 5 kernels, size of kernel: 5 by 5, input of this layer is a 3D tesnor (57, 47, 1), activation function is tanh <br>\n",
    "2)\tLayer 1 - maxpooling2d_1 (MaxPooling2D), 2 by 2 pooling <br>\n",
    "3)\tLayer 2 - conv2d_2 (Conv2D), 10 kernels, size of kernel: 5 by 5, activation function is tanh <br>\n",
    "4)\tLayer 3 - maxpooling2d_2 (MaxPooling2D), 2 by 2 pooling <br>\n",
    "5)\tLayer 4 - flatten_1 (Flatten) <br>\n",
    "6)\tLayer 5 - dense_1 (Dense), 1000 nodes, activation function is tanh <br>\n",
    "7)\tLayer 6 - dense_2(Dense), 40 nodes, activation function is softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN():\n",
    "    \n",
    "    # Your code goes here\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Train the convnet\n",
    "- Call `build_CNN` get the convnet model\n",
    "- Compile the modle (`compile()`, use the following hyperparameter setting to compile the model.<br>\n",
    "    1) `optimizer=rmsprop` <br>\n",
    "    2) `loss=categorical_crossentropy` <br>\n",
    "    3) `metrics=[‘accuracy’]`. <br>\n",
    "- Train the model (`fit()`). <br>\n",
    "    1) Apply **early stopping** in the learning/fitting process. Click [here](https://chrisalbon.com/deep_learning/keras/neural_network_early_stopping/) for a introduction of very basic use of early stopping. <br>\n",
    "    2) Plot the learning curve by using the returned result from `fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Plot learning curve on train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the loss curves\n",
    "\n",
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Make prediction\n",
    "Run the code below to evaluate the model and observe the prediction result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data, test_target)\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predict` function returns a probability distribution over all 40 subjects. How do we get the identity from the `predctions`, type the statement in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the label\n",
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many subjects are wrongly classified? Give the identity of those subjects?**\n",
    "\n",
    "Ans: **Type your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Task 2 - Build up your own convnet\n",
    "\n",
    "In this task you're to build your own model and train it on the cats and dogs images. Save and submit your best modle (`model.save()` can be used to save your modle onto the disk).\n",
    "\n",
    "### 2.1 Load Data\n",
    "This task focus on classifying images as dogs or cats, in a dataset containing 4,000 pictures of cats and dogs (2,000 cats, 2,000 dogs). We’ll use 2,000 pictures for training—1,000 for validation, and 1,000 for testing. The original dataset could be downloaded from www.kaggle.com/c/dogs-vs-cats/data <br>\n",
    "We'll use the split dataset which can be downloaded from the moodle course page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the folder of train, validation and test data set\n",
    "import os\n",
    "\n",
    "# Change the follwing path if the dataset is not located here\n",
    "train_dir = \"../dogvscat/train\"\n",
    "validation_dir = \"../dogvscat/validation\"\n",
    "test_dir = \"../dogvscat/test\"\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')  \n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ImageDataGenerator to read images from directories\n",
    "# The generator yields batches of 150 × 150 RGB images (shape (20, 150, 150, 3)) and binary labels (shape (20,)).\n",
    "# There are 20 samples in each batch (the batch size).\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Rescales all images by 1/255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size=(150, 150),\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bulid your convnet and Train it\n",
    "\n",
    "Design and implement your own model for classifying cats and dogs images. Save the trained model into the file `mymodel.h5`. <br>\n",
    "When calling `fit()`, `train_data, train_target` should be replace with `train_generator`, and use `validation_generator` to initialize parameter `validation_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the code below to load and evaluate your model\n",
    "\n",
    "model_stu = models.load_model('mymodel.h5')\n",
    "\n",
    "# test_generator\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=(150, 150),\n",
    "                                                  batch_size=20,\n",
    "                                                  class_mode='binary')\n",
    "model.evaluate(test_generator)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
